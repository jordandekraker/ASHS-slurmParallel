#!/bin/bash
#$ -S /bin/bash

#######################################################################
#
#  Program:   ASHS (Automatic Segmentation of Hippocampal Subfields)
#  Module:    $Id$
#  Language:  BASH Shell Script
#  Copyright (c) 2012 Paul A. Yushkevich, University of Pennsylvania
#  
#  This file is part of ASHS
#
#  ASHS is free software: you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation, either version 3 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU General Public License for more details. 
#  You should have received a copy of the GNU General Public License
#  along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
#######################################################################

# TODO:
#   - Check that the data are in the right orientation, or handle 
#     various orientations

function usage()
{
  cat <<-USAGETEXT
		ashs_main: automatic segmentation of hippocampal subfields
		usage:
		  ashs_main [options]

		required options:
		  -a dir            Location of the atlas directory. Can be a full pathname or a
		                    relative directory name under ASHS_ROOT/data directory. 
		  -g image          Filename of 3D (g)radient echo MRI (ASHS_MPRAGE, T1w)
		  -f image          Filename of 2D focal (f)ast spin echo MRI (ASHS_TSE, T2w)
		  -w path           Working/output directory

		optional:
		  -d                Enable debugging
		  -h                Print help
		  -s integer        Run only one stage (see below); also accepts range (e.g. -s 1-3)
		  -N                No overriding of ANTS/FLIRT results. If a result from an earlier run
		                    exists, don't run ANTS/FLIRT again
		  -T                Tidy mode. Cleans up files once they are unneeded. The -N option will
		                    have no effect in tidy mode, because ANTS/FLIRT results will be erased.
		  -I string         Subject ID (for stats output). Defaults to last word of working dir.
		  -V                Display version information and exit
		  -C file           Configuration file. If not passed, uses $ASHS_ROOT/bin/ashs_config.sh
		  -Q                Use Sun Grid Engine (SGE) to schedule sub-tasks in each stage. By default,
		                    the whole ashs_main job runs in a single process. If you are doing a lot
		                    of segmentations and have SGE, it is better to run each segmentation 
		                    (ashs_main) in a separate SGE job, rather than use the -q flag. The -q flag
		                    is best for when you have only a few segmentations and want them to run fast.
		  -q OPTS           Pass in additional options to SGE's qsub. Also enables -Q option above.
		  -G                Use SLURM (graham) to submit the jobs (requires neuroglia-helpers)
		  -z script         Provide a path to an executable script that will be used to retrieve SGE or
		                    GNU parallel options for different stages of ASHS. Takes precendence over -q
		  -P                Use GNU parallel to run on multiple cores on the local machine. You need to
		                    have GNU parallel installed.
		  -r files          Compare segmentation results with a reference segmentation. The parameter
		                    files should consist of two nifti files in quotation marks:

		                      -r "ref_seg_left.nii.gz ref_seg_right.nii.gz"

		                    The results will include overlap calculations between different
		                    stages of the segmentation and the reference segmentation. Note that the
		                    comparison takes into account the heuristic rules specified in the altas, so
		                    it is not as simple as computing dice overlaps between the reference seg
		                    and the ASHS segs.
		  -m file           Provide the .mat file for the transform between the T1w and T2w image. The file
		                    is in the format used by ITK-SNAP and C3D and should be generated by performing
		                    registration with the T2w MRI as fixed image and the T1w MRI as moving. 
		                    By default, the mat file is used as a hint to initialize rigid T2/T1
		                    but this can be modified with the -M flag.
		  -M                The mat file provided with -m is used as the final T2/T1 registration.
		                    ASHS will not attempt to run registration between T2 and T2.
		  -H                Tell ASHS to use external hooks for reporting progress, errors, and warnings.
		                    The environment variables ASHS_HOOK_SCRIPT must be set to point to the appropriate
		                    script. For an example script with comments, see ashs_default_hook.sh
		                    The purpose of the hook is to allow intermediary systems (e.g. XNAT) 
		                    to monitor ASHS performance. An optional ASHS_HOOK_DATA variable can be set
		                    and will be forwarded to the script

		Stages:
		  1:                fit to population template
		  2:                multi-atlas registration
		  3:                consensus segmentation using voting
		  4:                bootstrap registration
		  5:                bootstrap segmentation using voting
		  6:                segmentation Q/A
		  7:                volumes and statistics

		Environment Variables:
		  ASHS_ROOT         Path to the ASHS root directory
		  ASHS_HOOK_XXX     See documentation for -H above

		Misc Notes:
		  The ASHS_TSE image slice direction should be z. In other words, the dimension
		  of ASHS_TSE image should be 400x400x30 or something like that, not 400x30x400

		SGE Options:
		  You can have detailed control over SGE options by passing a custom shell script to the -z
		  option. ASHS will call this shell script with the working directory as the first parameter
		  and stage as the second parameter. The script should print to stdout the SGE (qsub) options
		  that should be used for this stage. This allows you to allocate resources for each stage.
	USAGETEXT
}

# Dereference a link - different calls on different systems
function dereflink ()
{
  if [[ $(uname) == "Darwin" ]]; then
    local SLTARG=$(readlink $1)
    if [[ $SLTARG ]]; then
      echo $SLTARG
    else
      echo $1
    fi
  else
    readlink -m $1
  fi
}

# Print usage by default
if [[ $# -lt 1 ]]; then
  echo "Try $0 -h for more information."
  exit 2
fi

# Clear the variables affected by the flags
unset ATLAS ASHS_MPRAGE ASHS_TSE ASHS_WORK STAGE_SPEC
unset ASHS_SKIP_ANTS ASHS_SKIP_RIGID ASHS_TIDY ASHS_SUBJID
unset ASHS_USE_QSUB ASHS_REFSEG_LEFT ASHS_REFSEG_RIGHT ASHS_REFSEG_LIST ASHS_USE_SLURM
unset ASHS_QSUB_OPTS ASHS_QSUB_HOOK
unset ASHS_INPUT_T2T1_MAT ASHS_INPUT_T2T1_MODE

# Set the default hook script - which does almost nothing
unset ASHS_USE_CUSTOM_HOOKS

# Special actions (e.g., print version info, etc.)
unset ASHS_SPECIAL_ACTION

# Read the options
while getopts "g:f:w:s:a:q:I:C:r:z:m:HNTdhVQPMG" opt; do
  case $opt in

    a) ATLAS=$(dereflink $OPTARG);;
    g) ASHS_MPRAGE=$(dereflink $OPTARG);;
    f) ASHS_TSE=$(dereflink $OPTARG);;
    w) ASHS_WORK=$(dereflink $OPTARG);;
    s) STAGE_SPEC=$OPTARG;;
    N) ASHS_SKIP_ANTS=1; ASHS_SKIP_RIGID=1; ;;
    T) ASHS_TIDY=1;;
    I) ASHS_SUBJID=$OPTARG;;
    Q) ASHS_USE_QSUB=1;;
    G) ASHS_USE_SLURM=1;;
    P) ASHS_USE_PARALLEL=1;;
    q) ASHS_USE_QSUB=1; ASHS_QSUB_OPTS=$OPTARG;;
    z) ASHS_USE_QSUB=1; ASHS_QSUB_HOOK=$OPTARG;;
    C) ASHS_CONFIG=$(dereflink $OPTARG);;
    H) ASHS_USE_CUSTOM_HOOKS=1;;
    r) ASHS_REFSEG_LIST=($(echo $OPTARG));;
    m) ASHS_INPUT_T2T1_MAT=$OPTARG;;
    M) ASHS_INPUT_T2T1_MODE=1;;
    d) set -x -e;;
    h) usage; exit 0;;
    V) ASHS_SPECIAL_ACTION=vers;;
    \?) echo "Unknown option $OPTARG"; exit 2;;
    :) echo "Option $OPTARG requires an argument"; exit 2;;

  esac
done

# Check the root dir
if [[ ! $ASHS_ROOT ]]; then
  echo "Please set ASHS_ROOT to the ASHS root directory before running $0"
  exit -2
elif [[ $ASHS_ROOT != $(dereflink $ASHS_ROOT) ]]; then
  echo "ASHS_ROOT must point to an absolute path, not a relative path"
  exit -2
fi

# Convert the work directory to absolute path
mkdir -p ${ASHS_WORK?}
ASHS_WORK=$(cd $ASHS_WORK; pwd)
if [[ ! -d $ASHS_WORK ]]; then 
  echo "Work directory $ASHS_WORK cannot be created"
  exit -2
fi

# Redirect output/error to a log file in the dump directory
LOCAL_LOG=$(date +ashs_main.o%Y%m%d_%H%M%S)
mkdir -p $ASHS_WORK/dump
exec > >(tee -i $ASHS_WORK/dump/$LOCAL_LOG)
exec 2>&1

# Write into the log the arguments and environment
echo "ashs_main execution log"
echo "  timestamp:   $(date)"
echo "  invocation:  $0 $@"
echo "  directory:   $PWD"
echo "  environment:"
set | grep "^ASHS_" | sed 's/^/    /'

# Handle the hook scripts
if [[ $ASHS_USE_CUSTOM_HOOKS ]]; then

  if [[ ! $ASHS_HOOK_SCRIPT ]]; then
    echo "ASHS_HOOK_SCRIPT must be set when using -H option"; exit -2
  fi

  if [[ ! -f $ASHS_HOOK_SCRIPT ]]; then
    echo "ASHS_HOOK_SCRIPT must point to a script file"; exit -2
  fi

  echo "Custom hooks requested with -H option"
  echo "  Hook script (\$ASHS_HOOK_SCRIPT): $ASHS_HOOK_SCRIPT"
  echo "  User data (\$ASHS_HOOK_DATA): $ASHS_HOOK_DATA"

else

  ASHS_HOOK_SCRIPT=$ASHS_ROOT/bin/ashs_default_hook.sh
  unset ASHS_HOOK_DATA

fi

# Check for the existence of the hook script
if [[ ! -x $ASHS_HOOK_SCRIPT ]]; then
  echo "ASHS hook script does not point to an executable (ASHS_HOOK_SCRIPT=$ASHS_HOOK_SCRIPT)"
  exit -2
fi

# Set the config file (from atlas if possible)
if [[ ! $ASHS_CONFIG ]]; then
  if [[ -f $ATLAS/ashs_user_config.sh ]]; then
    ASHS_CONFIG=$ATLAS/ashs_user_config.sh
  else
    ASHS_CONFIG=$ASHS_ROOT/bin/ashs_config.sh
  fi
fi

# Check that parallel and qsub are not both on
if [[ $ASHS_USE_PARALLEL && $ASHS_USE_QSUB ]]; then
  echo "Cannot use SGE (-Q) and GNU Parallel (-P) at the same time"
  exit -2
fi

# Load the library. This also processes the config file
source $ASHS_ROOT/bin/ashs_lib.sh

# Just print version?
if [[ $ASHS_SPECIAL_ACTION == "vers" ]]; then
  vers
  exit 0
fi

# Check if the required parameters were passed in
echo "Atlas    : ${ATLAS?    "Directory for atlas was not specified. See $0 -h"}"
echo "T1 Image : ${ASHS_MPRAGE?   "T1-weighted MRI was not specified. See $0 -h"}"
echo "T2 Image : ${ASHS_TSE?      "T2-weighted MRI was not specified. See $0 -h"}"
echo "WorkDir  : ${ASHS_WORK?     "Working directory was not specified. See $0 -h"}"

# Handle the -r parameter
if [[ $ASHS_REFSEG_LIST ]]; then
  if [[ ${#ASHS_REFSEG_LIST[*]} -eq 2 ]]; then
    ASHS_REFSEG_LEFT=$(dereflink ${ASHS_REFSEG_LIST[0]})
    ASHS_REFSEG_RIGHT=$(dereflink ${ASHS_REFSEG_LIST[1]})
    if [[ ! -f $ASHS_REFSEG_LEFT || ! -f $ASHS_REFSEG_RIGHT ]]; then
      echo "Reference segmentation $ASHS_REFSEG_LEFT $ASHS_REFSEG_RIGHT not found"
      exit -2
    fi
  else
    echo "Wrong number of parameters to -r option"
  fi
fi

# Handle the -m parameter
if [[ $ASHS_INPUT_T2T1_MAT ]]; then

  # Check that the file exists
  if [[ ! -f $ASHS_INPUT_T2T1_MAT ]]; then
    echo "Matrix file $ASHS_INPUT_T2T1_MAT specified with -m does not exist"
    exit -2
  elif [[ $ASHS_INPUT_T2T1_MODE -eq 1 ]]; then
    echo "User-supplied T2->T1 final transform: ${ASHS_INPUT_T2T1_MAT}"
  else
    echo "User-supplied T2->T1 transform hint: ${ASHS_INPUT_T2T1_MAT}"
  fi
fi

# Whether we are using QSUB
if [[ $ASHS_USE_QSUB ]]; then
  if [[ ! $SGE_ROOT ]]; then
    echo "-Q flag used, but SGE is not present."
    exit -1;
  fi
  if [[ $ASHS_QSUB_HOOK ]]; then
    if [[ ! -f $ASHS_QSUB_HOOK ]]; then
      echo "Parameter to -z ($ASHS_QSUB_HOOK) does not point to a file"
      exit 2
    fi
    echo "Using SGE with root $SGE_ROOT and callback script $ASHS_QSUB_HOOK"
  elif [[ $ASHS_QSUB_OPTS ]]; then 
    echo "Using SGE with root $SGE_ROOT and options \"$ASHS_QSUB_OPTS\""
  else
    echo "Using SGE with root $SGE_ROOT and default options"
  fi
elif [[ $ASHS_USE_PARALLEL ]]; then
  echo "Using GNU parallel"
 elif [[ $ASHS_USE_SLURM ]]; then
  echo " Using SLURM"
else
  echo "Not using SGE or GNU parallel"
fi

# Check the atlas location
if [[ -f $ATLAS/ashs_atlas_vars.sh ]]; then
  ASHS_ATLAS=$ATLAS;
elif [[ -f $ASHS_ROOT/data/$ATLAS/ashs_atlas_vars.sh ]]; then
  ASHS_ATLAS=$ASHS_ROOT/data/$ATLAS
else
  echo "Atlas directory must be specified"
  exit 2;
fi

# Check the heuristics in the atlas
if [[ -f $ASHS_ATLAS/ashs_heuristics.txt ]]; then
	ASHS_HEURISTICS=$ASHS_ATLAS/ashs_heuristics.txt
fi

# Make sure all files exist
if [[ ! $ASHS_MPRAGE || ! -f $ASHS_MPRAGE ]]; then
	echo "T1-weighted 3D gradient echo MRI (-g) must be specified"
	exit 2;
elif [[ ! $ASHS_TSE || ! -f $ASHS_TSE ]]; then
	echo "T2-weighted 2D fast spin echo MRI (-f) must be specified"
	exit 2;
elif [[ ! $ASHS_WORK ]]; then
	echo "Working/output directory must be specified"
	exit 2;
fi

# Check that the dimensions of the T2 image are right
DIMS=$(c3d $ASHS_TSE -info | cut -d ';' -f 1 | sed -e "s/.*\[//" -e "s/\].*//" -e "s/,//g")
if [[ ${DIMS[2]} > ${DIMS[0]} || ${DIMS[2]} > ${DIMS[1]} ]]; then
  echo "The T2-weighted image has wrong dimensions (fails dim[2] < min(dim[0], dim[1])"
  exit -1
fi

# Subject ID set to work dir last work
if [[ ! $ASHS_SUBJID ]]; then
  ASHS_SUBJID=$(basename $ASHS_WORK)
fi

# Create the working directory and the dump directory
mkdir -p $ASHS_WORK/final

# Set the start and end stages
if [[ $STAGE_SPEC ]]; then
  STAGE_START=$(echo $STAGE_SPEC | awk -F '-' '$0 ~ /^[0-9]+-*[0-9]*$/ {print $1}')
  STAGE_END=$(echo $STAGE_SPEC | awk -F '-' '$0 ~ /^[0-9]+-*[0-9]*$/ {print $NF}')
else
  STAGE_START=1
  STAGE_END=7
fi

if [[ ! $STAGE_END || ! $STAGE_START || $STAGE_START -le 0 || $STAGE_END -gt 7 ]]; then
  echo "Wrong stage specification -s $STAGE_SPEC"
  exit -1;
fi

# Get the number of atlases, other information
source $ASHS_ATLAS/ashs_atlas_vars.sh

# Check the atlas version
if [[ ! $ASHS_ATLAS_VERSION_DATE || \
  $ASHS_ATLAS_VERSION_DATE -lt $ASHS_OLDEST_COMPAT_DATE ]]; then
  echo "Your atlas was generated before ${ASHS_OLDEST_COMPAT_DATE} and"\
       "is not compatible with the current ASHS version. Please obtain"\
       "a newer version of the atlas or upgrade your atlas using the"\
       "script 'ashs_atlas_upgrade.sh'"
  exit 2;
fi

# List of sides for the array qsub commands below
SIDES="$ASHS_SIDES"

# Run the stages of the script
export ASHS_ROOT ASHS_WORK ASHS_SKIP_ANTS ASHS_SKIP_RIGID ASHS_SUBJID ASHS_CONFIG ASHS_ATLAS
export ASHS_HEURISTICS ASHS_TIDY ASHS_MPRAGE ASHS_TSE ASHS_REFSEG_LEFT ASHS_REFSEG_RIGHT QOPTS
export SIDES ASHS_HOOK_SCRIPT ASHS_HOOK_DATA
export ASHS_INPUT_T2T1_MAT ASHS_INPUT_T2T1_MODE

# List of training atlases 
TRIDS=$(for((i = 0; i < $ASHS_ATLAS_N; i++)); do echo $(printf "%03i" $i); done)

# Lengths of the different stages in terms of relative progress
STAGE_PPOS=(0.0 0.2 0.5 0.6 0.9 0.95 0.98 1.0)

# Names of the different stages
STAGE_NAMES=(\
  "Normalization to T1 population template" \
  "Initial ROI registration to all T2 atlases" \
  "Initial joint label fusion" \
  "Boostrapped ROI registration to all T2 atlases" \
  "Boostrapped joint label fusion" \
  "Final QA" \
  "Statistics and volume computation")

# If starting at stage other than 1, check for the correct output of
# the previous stages
if [[ $STAGE_START -gt 1 ]]; then

  # Run the validity check
  ashs_check_main $((STAGE_START-1)) || exit -1

else

  # Check the validity of the atlas
  ashs_check_atlas || exit -1

fi

# Run the various stages
for ((STAGE=$STAGE_START; STAGE<=$STAGE_END; STAGE++)); do

  # Figure out the progress range for the specified batch
  ASHS_BATCH_PSTART=${STAGE_PPOS[$((STAGE-1))]}
  ASHS_BATCH_PEND=${STAGE_PPOS[$STAGE]}
  export ASHS_BATCH_PSTART ASHS_BATCH_PEND

  # The desription of the current stage
  STAGE_TEXT=${STAGE_NAMES[STAGE-1]}
  echo "****************************************"
  echo "Starting stage $STAGE: $STAGE_TEXT"
  echo "****************************************"

  # Put together qsub options for this stage
  if [[ $ASHS_USE_QSUB ]]; then

    # Is there a callback script
    if [[ $ASHS_QSUB_HOOK ]]; then
      QOPTS="$(bash $ASHS_QSUB_HOOK $ASHS_WORK $STAGE)"
      echo "Qsub options for this stage: $QOPTS"
    else
      QOPTS="${ASHS_QSUB_OPTS}"
    fi
  fi

  # Send the informational message via hook
  bash $ASHS_HOOK_SCRIPT info "Started stage $STAGE: $STAGE_TEXT"

  JOBLIST_OPTS="-t"
  if [ -n "$JOB_DEPENDS" ]; then
	JOBLIST_OPTS="$JOBLIST_OPTS -d afterany:$JOB_DEPENDS"
  fi

  case $STAGE in 

    1) 
    # Template matching
    qsubmit_sync "ashs_stg1" $ASHS_ROOT/bin/ashs_template_qsub.sh
    if [[ ! $ASHS_USE_SLURM ]]; then
	JOB_DEPENDS=$(joblistSubmit $ASHS_WORK/joblist.ashs_stg1 $JOBLIST_OPTS )
    fi	

    ;;

    2) 
    # Multi-atlas matching 
    qsubmit_double_array "ashs_stg2" "$SIDES" "$TRIDS" $ASHS_ROOT/bin/ashs_multiatlas_qsub.sh
    if [[ ! $ASHS_USE_SLURM ]]; then
	JOB_DEPENDS=$(joblistSubmit $ASHS_WORK/joblist.ashs_stg2 $JOBLIST_OPTS )
    fi	

    ;;

    3) 
    # Voting
    qsubmit_single_array "ashs_stg3" "$SIDES" $ASHS_ROOT/bin/ashs_voting_qsub.sh 0
    if [[ ! $ASHS_USE_SLURM ]]; then
	JOB_DEPENDS=$(joblistSubmit $ASHS_WORK/joblist.ashs_stg3 $JOBLIST_OPTS )
    fi	


    ;;

    4)
    # Bootstrapping
    qsubmit_double_array "ashs_stg4" "$SIDES" "$TRIDS" $ASHS_ROOT/bin/ashs_bootstrap_qsub.sh
    if [[ ! $ASHS_USE_SLURM ]]; then
	JOB_DEPENDS=$(joblistSubmit $ASHS_WORK/joblist.ashs_stg4 $JOBLIST_OPTS )
    fi	


    ;;

    5)
    # Bootstrap voting
    qsubmit_single_array "ashs_stg5" "$SIDES" $ASHS_ROOT/bin/ashs_voting_qsub.sh 1
    if [[ ! $ASHS_USE_SLURM ]]; then
	JOB_DEPENDS=$(joblistSubmit $ASHS_WORK/joblist.ashs_stg5 $JOBLIST_OPTS )
    fi	


    ;;

    6)
    # Final QA
    qsubmit_sync "ashs_stg6" $ASHS_ROOT/bin/ashs_finalqa_qsub.sh
    if [[ ! $ASHS_USE_SLURM ]]; then
	JOB_DEPENDS=$(joblistSubmit $ASHS_WORK/joblist.ashs_stg6 $JOBLIST_OPTS )
    fi	

    ;;
  
    7) 
    # Statistics & Volumes
    qsubmit_sync "ashs_stg7" $ASHS_ROOT/bin/ashs_extractstats_qsub.sh
    if [[ ! $ASHS_USE_SLURM ]]; then
	JOB_DEPENDS=$(joblistSubmit $ASHS_WORK/joblist.ashs_stg7 $JOBLIST_OPTS )
    fi	


    ;;

  esac  

  # Run the validity check
  ashs_check_main $STAGE || exit -1

done
